The main objectives of this thesis were to develop a general method applicable to a wide range of GLMMs, allowing complex covariance structures in the random effects, and to provide interpretable and trustworthy results. In addition, the method should be easily accessible for researchers across disciplines, and be computationally feasible in most applications. Our attempt to reach these objectives has culminated in the Bayesian Variable Importance method, which is a novel framework for estimating relative variable importance in generalized linear mixed models. The work presented in this thesis is motivated by the increased inference possible in the Bayesian framework and partially builds on the author's previous work in \citet{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024} and that of \citet{matre}.
\\
\\
\subsection*{Summary of contributions} 
The development of the BVI method involved utilizing the relative weights method \citep{johnson_relative_weights} to project the fixed covariates into an orthogonal space. The projection, or approximation, of these covariates is used to fit the model, before a back-transformation is applied to relate the estimated results back to the original covariate space. To obtain inference on the Bayesian GLMMs, we translated frequentist concepts, such as the $R^2$ measure, to fit in the Bayesian framework. This translation has been inspired by the work in \citet{gelman2017rsquared}, but is also a result of the author's own work. Once the methodology was developed, we revisited a Gaussian simulation study from \citet{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024}. This simulation study gave us indications that the BVI method was sound for the LMMs, and so it was applied to a real world dataset. The dataset, gathered from house sparrows on the Helgeland coast, Norway, was used to investigate the heritability properties of the sparrow population. We found that the BVI method was in close agreement with other heritability studies, which was reassuring. In addition to calculating the heritability, we demonstrated how the BVI method allows for a more in depth analysis, by sampling the posterior relative importance distributions of all covariates used in the model. Moving from the LMMs to the GLMMs, we conducted a simulation study for the binomial and Poisson GLMMs in which the underlying structure was known. The results from the simulation study were promising and were compared to the \texttt{rptR} package, a similar relative importance measure, in the frequentist framework. Following this, a separate case study using \texttt{rptR} was conducted. This study showed that while the BVI method and the \texttt{rptR} method gave quite similar results, the BVI method allows for a more thorough assessment of the covariates and assigns values of importance to each of the fixed effects separately. Hopefully, this is advantageous for the researcher using the BVI method, as it allows for a more detailed analysis of the covariates. Lastly, we explored how similar the BVI method was to related Bayesian methods that use shrinkage priors. The results showed that the R2D2 and GDR2 methods contain very large uncertainty, and so we argue that the BVI method is a more suitable choice for estimating relative variable importance. This is not surprising, as the shrinkage prior methods were not specifically developed for variable importance. 
\\
\\
The full methodology has been implemented in the statistical software R, and is available as the R package \texttt{BayesianVariableImportance} on the authors GitHub, with a link to the repository provided in \Cref{ap:github-repository}. In \Cref{ap:bayesian-importance} a usage example of the package is supplied, which is also available on the authors GitHub along with all code used to obtain the results of this thesis.
\\
\\
Being a general method, our aspirations are that the BVI method will be applied by researchers across disciplines that are interested in the statistical properties of covariates in GLMMs. The BVI method does not aim to give researchers an exact measure of variable importance, but rather to provide posterior distributions of relative importance that should be interpreted by the researcher in the field of application. As the distributions will naturally have an uncertainty, it is advantageous if this uncertainty is assessed and understood as a part of the analysis. Hopefully, this can give broader inference on the importance of the covariates, which will in turn lead to more informed conclusions on the effect of covariates on a response. In itself, the BVI poses an analogue to the frequentist relative variable importance measure \texttt{rptR} for non-Gaussian responses, but with the added benefit of directly estimating the relative importance distributions of fixed effects. Further, for Gaussian data, it also poses an analogue to more established methods such as the LMG method \citep{gromping_relaimpo}, the extended LMG method \citep{matre} and the extended relative weights method \citep{matre} as discussed in \citet{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024}. Lastly, the BVI method allows one to specify covariance structures in the random effects, which can be beneficial when modeling complex data structures.
\\
\\
\subsection*{Assessment and validation}
For relative variable importance measures, some criteria are found in \Cref{sec:rel_imp} that it is desirable to fulfill. The simulation study on Gaussian LMMs (\Cref{sec:simulations}) shows that the BVI method compares very nicely to the robust LMG method, as well as its extension and the extension of the relative weights method. We argue, as in \citet{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024}, that this is a promising result. Although no theoretical results were derived, one could argue that the simulation study implies that the BVI method gives a proper decomposition, at least in expectation. This is perhaps the most fundamental criterion, as decomposing the $R^2$ is the main objective of the BVI method.
% It was argued in \citet{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024} that the simulation study on Gaussian LMMs (\Cref{sec:simulations}) gave promising results of the BVI method fulfilling the proper decomposition criteria.
When assessing how the BVI method performs on GLMMs, in which the response variance is not on the same scale as the covariates, this criterion is hard to assess. Instead of aiming to decompose the total model variance, we find it natural to rather aim for a proper decomposition of the models $R^2$ on the latent scale. From the definition of $R^2$ for GLMMs in \citet{nakagawa2013general}, the simulation study shows that the posterior distributions of the marginal and conditional $R^2$ are generally symmetrically distributed around the expected $R^2$ value. As the $R^2$ values in our thesis are constructed from the relative importance assigned to covariates, this indicates that the allocation of relative importance is sensible. Based on these observations, we argue that the BVI method, in posterior expectation, is capable of providing a satisfactory decomposition of the $R^2$ in GLMMs. Further, the results from the simulation studies for the isolated covariates and the $R^2$ strengthen our belief that the BVI method correctly captures the expected patterns for different correlation levels. Consequently, we argue that the BVI method allocates the covariates with a plausible relative importance, both for Gaussian and non-Gaussian models.
The non-negativity criterion is fulfilled by recalling that the relative importance estimates of fixed effects are squared, and no variance estimate for random effects can be negative. Consequently, the posterior relative importance distributions will not contain negative values. As discussed in \citet{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024}, the exclusion on will not be used in our assessment, as \citet{gromping_relaimpo} argues this is not in general reasonable. Lastly, violating  the inclusion criterion is seen as unlikely to occur in practice, although it is mentioned in \citet{matre} that the extensions of the LMG method and the relative weights method can violate this criterion. It has not yet been properly assessed how the inclusion criterion applies to the BVI method. 
\\
\\
A suggestion that was debated in \citep{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024} is whether one should directly translate the desirable criteria for relative importance measures in the frequentist framework to the Bayesian framework. The Bayesian framework is designed to provide uncertainty, and therefore subjecting its result against a rigid threshold of containing or not containing zero is not necessarily reasonable. In the case of the inclusion criterion, we interpret this to mean that if the posterior relative importances of a non-zero regressor contains zero, this is a violation the criterion. By not considering the inclusion criterion, zero values in the relative importance distributions of a non-zero regressor would require the researcher to carefully assess the covariate. A careful evaluation of the results is in line with what we intend the BVI method to invoke, and therefore the violation of the inclusion criterion might not pose a problem at all. With this in mind, the results both the Gaussian and non-Gaussian simulation studies show that the BVI method produces results that align well with what we expect, and that the results are plausible. Therefore, we believe that for most practical applications, the general idea behind the criteria of variable importance measures are fulfilled by the BVI method. 
\\
\\
Another part of validating the BVI method is to assess how well the methodology performs on real data. To investigate this, we applied the BVI method to an LMM modelling three phenotypic traits of a house sparrow population. The modelling of phenotypic traits included complex correlation structures between related birds, so the model formulation and pedigree was constructed with the help of domain experts. For each trait, the BVI method estimated the posterior relative importance distributions for all covariates in the model, with the heritability of each trait being of particular interest. The heritability estimates from the BVI method were compared to those of \citet{Silva2017} and \citet{Muff2019Genetic}. For all traits the posterior distribution of the heritability from the BVI method covers the estimates from the domain experts, and places them close to the mean. We observed that the average heritability estimate for body mass from the BVI method was narrowly smaller than both estimates from \citet{Silva2017} and \citet{Muff2019Genetic}. Investigating the wing length, the average heritability estimated by the BVI method was marginally larger than that of \citet{Muff2019Genetic} and a bit smaller than the estimate from \citet{Silva2017}. The average heritability estimate for tarsus length was very close to the estimates from \citet{Silva2017}, and in this case \citet{Muff2019Genetic} had no estimate. All posterior distributions of heritability were seemingly normally distributed, with some varying spread and kurtosis. That the BVI method is in such close agreement with estimates from published papers by domain experts is very promising, and strengthens our belief that the methodology and implementation can be used in practice.
\\
\\
While the house sparrow study was particularly interested in heritability values, our methodology's true strength lies in its ability to extend this analysis to the broader concept of relative variable importance. The BVI method allows researchers to evaluate the relative variable importance of all covariates in the models, not limited to a specific measure. This comprehensive approach provides additional information that can help researchers gain a deeper understanding of the statistical models they apply. Importantly, this capability is not limited to quantitative genetics. The BVI method presents a general framework for relative importance of covariates in generalized linear mixed models (GLMMs), regardless of the context. Given the promising results observed so far, we believe that the methodology is robust, which supports its potential for application in many disciplines.
\\
\\
It was difficult to find a real world example to compare the binomial and Poisson GLMMs to. The solution was to compare the BVI method to the \texttt{rptR} method in a case study on repeatability as well as in the non-Gaussian simulation study where the package was applicable. The case study was created by the authors of the \texttt{rptR} package, which suggests a repeatability measure for GLMMs. As repeatability is closely linked to relative variable importance, it was possible to use the package in such a way that it could be compared to the BVI method. In the case study, the BVI method and the \texttt{rptR} package closely agreed for both the binomial and Poisson models. The spread of the posterior repeatability from the BVI method was more narrow than the confidence interval from the \texttt{rptR}. In terms of computational efficiency, the BVI method was significantly faster than all the models from \texttt{rptR} as it does not need to bootstrap to quantify the uncertainty. When using the \texttt{rptR} package for comparisons in the simulation study, the overall results aligned well with the BVI method, with some small exceptions. For the random effects, we observed some differences that were relatively large compared to the average allocated relative importance for positive correlations. The same could be said for the distributions of $R^2$, however these differences were smaller relative to the average $R^2$ estimates. Overall, the BVI method was more in line with the expected results than the \texttt{rptR} package, and demonstrated significantly faster computational performance.  
\\
\\
The field of Bayesian variable importance measures for regression models is not very large, but there has been some research on the topic. Specifically, the use of continuous shrinkage priors for linear models of high dimension has attracted attention \citep{aguilar2024generalized}. Two priors that can be applied as continuous shrinkage priors and that have favorable properties for variable importance are the $R^2$-induced Dirichlet Decomposition (R2D2) priors \citep{zhang2020bayesian} and its generalization to Generalized Decomposition $R^2$ (GDR2) priors. Through a simulation study on a linear regression model, the use of R2D2 and GDR2 priors were compared to the BVI method with the LMG method as a benchmark. The results show that the R2D2 and GDR2 priors are not very rigid, by estimating almost uniform distributions of relative posterior variable importance. The almost uniform distribution may not be reasonable for relative variable importance, but it is sensible for cases where there is little or no prior information available. The shrinkage prior methods generally do not follow the patterns we see from the BVI and the Relaimpo methods, and yield estimates with large uncertainty. We argue that for the specific task of assigning relative variable importance, the BVI method is more suitable and more reliable than the R2D2 and GDR2 methods. However, the use of these shrinkage priors are primarily not focused on calculating the specific variable importance. Shrinkage prior methods could perhaps be developed further, with an emphasis on variable importance, to yield more suitable estimates for posterior relative variable importance distributions. As the BVI method and the shrinkage prior methods have been developed for different purposes, the R2D2 and GDR2 methods differ from the BVI method in some fundamental ways. Firstly, to our knowledge, the shrinkage prior methods have yet to be applied for GLMMs and so direct comparison for the most complex models is not possible. Further, we sample values of coefficients and random effects a posteriori and then estimate the relative importances based on the samples. This means that the estimates from the model are used, which in most cases do not vary greatly for different model fits to the data. On the other hand, the R2D2 and GDR2 priors consider the relative variable importance as a parameter in the model, and therefore places prior values on the relative variable importance directly. When placing the priors directly on the importance, one must keep in mind that the choice of priors are the most criticized topic in Bayesian statistics \citep{robert2007bayesian}. Considering that the user is often not informed about the underlying mechanism in the relative variable importance parameter, we assume that they will parameterize the priors in such a way that they reflect the lack of information. Therefore, we see it as sensible that the users initial lack of precision propagates into the final posterior distribution of relative variable importance. This could be a reason why the estimates for the shrinkage priors are more spread out than estimates for the BVI method. Moreover, the priors themselves differ, as the R2D2 and GDR2 priors are continuous shrinkage priors, which are designed to shrink small effects towards zero. We use penalising complexity priors, which puts the emphasis on the complexity of the model. This means the general idea for the priors used is the same, but the implementation and interpretation of their results are different. Lastly, it should be mentioned that the results in this thesis are based on the author's interpretation of how the shrinkage priors can be used for relative variable importance. The author gained this knowledge by reading the papers \citet{zhang2020bayesian} and \citet{aguilar2024generalized}, and by discussing the topic with the authors of \citet{aguilar2024generalized}. Therefore, we believe that one could further optimize the use of shrinkage priors for variable importance by further studying the topic.
\\
\\
\subsection*{Limitations}
It could be questioned if our investigations of the Bayesian Variable Importance method has been sufficient. In the Gaussian simulation study, we chose to investigate covariates that were highly correlated, whereas in the non-Gaussian we looked into more moderate correlation levels, including negative correlation. Arguably, we should have looked into negative correlation for the Gaussian simulation study, and more extreme correlation levels for the non-Gaussian study. However, with limited time and resources, we had to make some choices. We believe that the correlation levels used in the simulation studies were sufficient to show the general performance of the BVI method.
\\
\\
Another topic of discussion, regards choice of priors. It would be natural, given more time, to investigate how different priors would perform and also if one could tune the hyperparameters of the priors applied. As priors are a large research field in itself, a thorough analysis of prior effects on the BVI method was not performed. We chose to follow the recommendations of \citet{simpson2017penalising} to use penalising complexity priors, as these had desirable properties and are designed to nicely fit INLA models \citep{simpson2017penalising}. The parameters of our PC priors follow the default values in the \texttt{R-INLA} package, and we have not investigated how these could be tuned to better fit the data. This could be done to further solidify the results of the BVI method, but would also require more time and resources than what was available in the scope of this thesis. 
\\
\\
Many of the foundational calculations made in the BVI method rely on approximations and sampling. The relative weights method can be viewed an approximation of the Lindemann, Merenda and Gold (LMG) method, and the accuracy of INLA is dependent on how well the marginals are approximated. It is to be expected that the errors made in these approximations are propagated to the outputted results of the BVI method. Further, the integration strategy used to compute the marginal posterior distributions of covariates, which again is used to approximate the joint posterior, can affect the sampled values. The samples may either be compromised by poor numerical integration due to a high dimensional hyperparameter vector, or perhaps the assumption of the latent layer being Gaussian is not met, causing the samples to not be representative of the true posterior. During the development of the BVI package, we experienced that the choice of integration strategy could have an impact on the results. For instance, in the house sparrow study, the grid and CCD integration strategies yielded different shapes of the posterior distributions of relative importance for some traits (\Cref{sec:supplementary_sparrows}). Although the distributions were centered around the same mean, one might interpret the results differently as a consequence of the different shapes. This exemplified the sensitivity of the BVI method to the chosen strategy, and is something the researcher should be aware of when applying the method. 
\\
\\
Despite these limitations, we argue that the results obtained from the BVI method are satisfactory. For the simulation studies, the results align well with our expectation in cases where we can give an expectation. Further, the patterns for varying correlation levels seem to be logical, and the results plausible, even though a true value is hard to obtain. Based on this, we believe that the BVI method can pose a useful tool, which is accurate enough for moderate correlation levels and does not require extensive prior tuning.
\\
\\
\subsection*{Further work}
We are not aware of a similar variable importance tool for Bayesian GLMMs as the BVI method. Therefore, there is still much work to be done in this field, and many opportunities for expanding the BVI method. Currently, we have implemented the BVI method to handle Gaussian, binomial and Poisson distributed responses, but there are a number of other distributions that could be of interest. In \citet{nakagawa2017}, the quasi-Poisson, negative binomial and Gamma distributions are analysed, so these would be natural extensions. Further, extending the BVI to also handle multiplicative overdispersion would allow the user to specify if the overdispersion should be modelled as additive or multiplicative and would be a valuable addition.
\\
\\
Although not developed for relative variable importance, the shrinkage priors R2D2 and GDR2 could be further explored to see if they can pose as viable variable importance measures. Recently, the author was also introduced to the article \citet{Fuglstad2020_joint_priors}. In the article, a framework for selecting priors based on a hierarchical decomposition of total model variance is proposed \citep{Fuglstad2020_joint_priors}. When prior knowledge is not available, the authors use the Dirichlet decomposition as the R2D2 method, however penalising complexity (PC) priors are used if the user has a logical idea of how to decompose the variance. In addition to using PC priors, the method proposed is designed for latent Gaussian models, which are both features of the BVI method when using INLA to fit the Bayesian GLMM. Therefore, the method by \citet{Fuglstad2020_joint_priors} could be of interest as a possible bridge between the BVI method and the discussed shrinkage prior methods. Due to time constraints, this was not investigated further in this thesis, but could be valuable to explore in the future.
\\
\\
It was also desirable in \citet{Arnstad:Relative_variable_importance_in_Bayesian_linear_mixed_models:2024}, to go deeper in to the theoretical properties that the BVI method possesses. As the BVI method is first and foremost a tool for researchers, the main focus of this thesis was put on developing a credible variable importance measure and wrap this in an R package so that it could be applied. Due to the complexity of this, the time and resources did not allow for full theoretical investigations of the BVI method. More theoretical investigations would be of very high interest, in particular some proofs in expectation for the variable importance estimates would be helpful, to further solidify the credibility of the method. 
\\
\\
We did not consider random slopes when developing the BVI method, but this could also be a possibility for further work. As the random slopes are often associated with a fixed effect, the correlation structure one obtains with random slopes is much more complex than that of random intercepts. This could be a difficult challenge to implement, but as discussed in \Cref{sec:R2_LMM}, the proposal by \citet{Johnson2014} could be a good starting point.
\\
\\
Conceptually, variable importance is in itself a debated topic. The first question one can ask is what the definition of relative importance is. In \citet{gromping_relaimpo}, relative importance is based on variance decomposition, and we have chosen to follow this notion. However, this definition has the disadvantage that an agreement of allocation of importances for correlated covariates seems impossible \citep{Gromping_2015}. This problematic issue is present in our results when the fixed effects were correlated, making evaluation of the method difficult. For our method, the pattern observed was a consequence of the relative weights method, rather than a general method for distributing the shared variance between covariates. The search for a unified variable importance framework has given us methods such as the LMG \citep{gromping_relaimpo}, Proportional marginal variance decomposition (PMVD) \citep{gromping_relaimpo}, the relative weights method \citep{johnson_relative_weights} and dominance analysis methods \citep{budescu1993dominance}. Yet, no one has been able to provide a method that is completely accepted by the field of mathematics. For these reasons, variable importance as a subject, and its methods, have received criticism \citep{gromping_relaimpo}. However, we believe that variable importance methods can give researchers very valuable practical insight and spark ideas, and that they therefore should have a place in the statistical toolbox. That being the case, we wish to emphasize that all statistical methods are limited by the assumptions they rely on and the data they are applied to. As \citet{Sutherland_91} put it; \textit{"Statistical techniques do not build theory - theoreticians do"}.


% \begin{itemize}
%     \item Summarize the method. Similar to that of the project thesis. 
%     \item State that it can be used across diciplines, and that a Bayesian approach is useful when prior information is available.
%     \item Now the discussion really begins. State that the methodology for LMMs proved to imply that we have a proper decomposition of the $R^2$. Even though this was not a main focus in this thesis, the results of uncorrelated covariates and marginal and conditional $R^2$ values seem to be in line with the what one would expect. 
%     \item State that we have addressed two main points from the project thesis, namely testing the methodology on real data and expanding it to handle GLMMs.
%     \item Further, we allow for a covariance structure in the random effects, which is not possible in the project thesis.
%     \item Emphasize that the results in this thesis are calculated based on theory from a subject that in itself has been subject to criticism. Therefore, the results should be interpreted with caution, especially when we also use the definitions of $R^2$ from Nakagawa, which may be oversimplified. (See last discussion section of project thesis)
% \end{itemize}

% Further work:
% \begin{itemize}
%     \item Extend the package to encompass the models with known distributional variance as in \citet{nakagawa2013general} and \citet{nakagawa2017}.
%     \item No proofs were considered due to time limitation
%     \item Random slopes could be featured, at least if one can say they improve the model.
%     \item Correlated random effects (?)
% \end{itemize}

% DET BØR NEVNES AT USIKKERHETEN I RESULTATENE FRA BVI ER GANSKE SMÅ OFTE, SÆRLIG NÅR DATAEN ER SIMULERT, OG AT DET SÅLEDES IKKE KAN SIDESTILLES MED ET KONFIDENSINTERVALL.


% HUSK Å NEVNE AT DET ER HELT NATURLIG AT VI FÅR RESULTATER SOM VARIERER LITT FRA GANG TIL GANG. DETTE KAN FORKLARE HVORFOR VI FOR EKSEMPEL IKKE TREFFER STOFFELS ESTIMATER OG BIOLOGENES ESTIMATER, MEN, BASERT PÅ SIMULERINGSSTUDIEN, FØLER VI OSS TRYGGE PÅ AT DENNE SPREDNINGEN IKKE ER FOR STOR, OG AT EN KJØRING AV METODEN KAN SEES PÅ SOM EN TILFELDIG PRØVE FRA EN FORDELING SOM ER SENTRERT RUNDT DEN KORREKTE VERDIEN.

% LEGG TIL TO GITHUB LINKER, EN FOR PAKKEN OG EN FOR MASTEREN.

% KAN DISKUTERES OM VI BURDE UNDERSØKT BEDRE PRIORS FOR ANIMAL MODEL OG DE ANDRE SIMULERINGENE
% KAN DISKUTERES OM VI BURDE BRUKT HØYERE KORRELASJON, MEN DA TROR JEG IKKE MODELLENE VILLE BLITT KONVERGENTE
% JEG TROR METODEN HELT FINT KLARER KATEGORISKE KOVARIATER NÅR DUMMY ENCODING BRUKES

% DISKUTER SHRINKAGE PÅ RANDOM EFFECTS MED POSITIVT KORRELERTE FIXED EFFECTS OG INCREASE PÅ NEGATIVT KORRELERTE
% DISKUTER HVORFOR POISSON MED HØY KORRELASJON GIR SÅ RARE RESULTATER

%All code used to produced the presented results can be found on the authors Github, and a link to the repository is provided in \Cref{ap:github-repository_thesis}. In the Github, the fully developed package is available, with all files found in the repository linked in \Cref{ap:github-repository_package}. To make it easy to apply, the author has provided a usage example of the package in \Cref{ap:bayesian-importance}. This covers installation, simulates data, formulates and fits a model before drawing samples and obtaining relative importance plots and summary statistics. 

% When the correlation between fixed effects is $0.4$, we see that the $R^2$ estimates from the Poisson model are slightly smaller on average than the expected value. The average is of course effected by the model fitting problems causing the estimated $R^2$ values to be artificially small. Therefore, it is plausible that for a good model fit, the BVI method will give estimate the $R^2$ values closer to what one might expect.

