


The work presented has extended the authors previous work in \citet{Arnstad} such that the Bayesian Variable Importance method proposes a framework for estimating relative variable importance in generalized linear mixed models. With the extensions, the BVI method is capable of handling more complex models, while at the same time proving to be computationally efficient. A Bayesian approach to variable importance has involved utilizing the relative weights method \citep{johnson_relative_weights} to project the fixed covariates into an orthogonal space. The projection, or approximation, of these covariates are used to fit the model, before a back-transformation is applied to relate the estimated results back to the original covariate space. To obtain inference on the Bayesian GLMMs, we have translated frequentist concepts, such as the $R^2$ measure, to fit in the Bayesian framework. This translation has been inspired by the work in \citet{gelman2017rsquared}, but is also a result of the authors own work. Once the methodology was developed, a simulation study was conducted in which the underlying structure was known. After a simulation study, the method was applied to a case study in which we could compare the model to a similar relative variable importance measure, \texttt{rptR}, in the frequentist framework. Lastly the method was applied to a dataset gathered from house sparrows on Helgelandskysten, Norway, to investigate the heritability properties of the sparrow population. The methodology has been implemented in an R package, \texttt{BayesianVariableImportance}, which is available in full on the authors Github, with a link to the repository provided in \Cref{ap:github-repository}. In \Cref{ap:bayesian-importance} a usage example of the package is supplied, which is also available on the authors Github along with all code used to obtain the results of this thesis.
\\
\\
Being a general method, our aspirations are that the BVI method will be applied by researches across disciplines that are interested in the statistical properties of covariates in GLMMs. The BVI method does not aim to give researchers an exact measure of variable importance, but rather provide posterior distributions that should be interpreted with domain knowledge. As the distributions will naturally have an uncertainty, it is advantageous if this uncertainty is interpreted and assessed as a part of the analysis. Hopefully, this can give broader inference on the importance of the covariates, which will in turn lead to more informed conclusions on the effect of covariates on a response. In itself, the BVI poses an analogue to the frequentist relative variable importance measure \texttt{rptR} for non-Gaussian responses, but with the added benefit of directly estimating the relative importance distributions of fixed effects. Further, for gaussian data, it also poses an analogue to more established methods such as the LMG method \citep{gromping2006relative}, the extended LMG method \citep{matre} and the extended relative weights method \citep{matre} as discussed in \citet{Arnstad}. Lastly, the BVI method allows one to specify covariance structures in the random effects, which can be beneficial when modeling complex data structures.
\\
\\
Discuss the shrinkage prior methods compared to our method.
\\
\\
For relative variable importance measures, some criteria are found in \Cref{sec:rel_imp} that it is desirable to fulfill. It was argued that the simulation study in \citet{Arnstad} gave promising results of the BVI method fulfilling the proper decomposition criteria. When assessing how the BVI method performs on GLMMs, in which the response variance is not on the same scale as the covariates, this criteria is hard to assess. From the definition of $R^2$ for GLMMs in \citet{nakagawa2013general}, the simulation study shows that the posterior distributions of the marginal and conditional $R^2$ are generally symmetrically distributed around the expected $R^2$ value. When the correlation between fixed effects is $0.4$, we see that the $R^2$ estimates from the Poisson model are slightly smaller on average than the expected value. The average is of course effected by the model fitting problems causing the estimated $R^2$ values to be artificially small. Therefore, it is plausible that for a good model fit, the BVI method will give estimate the $R^2$ values closer to what one might expect. Based on these observations, we argue that the BVI method, in posterior expectation, is capable of providing a satisfactory decomposition of the $R^2$ in GLMMs. The non-negativity criteria is fulfilled by recalling that the relative importance estimates of fixed effects are squared, and no variance estimate for random effects can be negative. Consequently, the posterior relative importance distributions will not contain negative values. As discussed in \citet{Arnstad}, the exclusion criteria will not be used in our assessment, as \citet{gromping_relaimpo} argues this is not in general reasonable. Lastly, violating  the inclusion criteria is seen as unlikely to occur in practice, although it is mentioned in \citet{matre} that the extensions of the LMG method and the relative weights method can violate this criteria. It has not yet been properly assessed how the inclusion criteria applies to the BVI method. A suggestion that was debated in \citep{Arnstad} is whether one should directly translate the desirable criteria for relative importance measures in the frequentist framework to the Bayesian framework. In the case of the inclusion criteria, we interpret this to mean that if the posterior relative importances of a non-zero regressor contains zero, this is a violation the criteria. The Bayesian framework is designed to provide uncertainty, and therefore subjecting its result against a rigid threshold of containing or not containing zero is not necessarily reasonable. By not considering the inclusion criteria, the inclusion of zero values in the relative importance distributions of a non-zero regressor would require the researcher to carefully assess the covariate. This is in line with what we intend the BVI method to invoke, and therefore the violation of the inclusion criteria might not pose a problem at all. With this in mind, the results of the simulation study show that the BVI method produces results that align well with what we expect, and that the results are plausible. 
\\
\\
It could be questioned if our investigations of the Bayesian Variable Importance method has been sufficient. For example, in the simulation study we do not allow for more extreme correlation levels than $-0.4$ and $0.4$. This is not a very large value, and therefore some analysis on the method for higher correlation levels could be of interest. The reasoning behind using such moderate correlation levels, is that the model fitting procedure was often compromised for more correlated covariates. As mentioned in the results, we experienced model crashes for a correlation of $0.4$, and the frequency of crashes rose when testing with higher correlation. It is therefore not clear how well the model will perform if covariates share much information, but results for an LMM with correlation levels of $0.9$ can be found in \citet{Arnstad}. Further, our initial idea was to also include a binomial model with the probit link function in the simulation thesis. This idea was abandoned due to severe model fitting problems, in which INLA would not converge. This was of course unfortunate, but as the result could not be trusted, we chose to ommit them from the thesis. We do however believe that if the probit model had been a good fit, the method would be able to calculate the relative importances in a similar manner as for the logit model. 
\\
\\
Another question one should ask, regards the priors. It would be natural, given more time, to investigate how different priors would perform and also if one could tune the hyperparameters of the priors applied. As priors are a large subject in themselves, a thorough analysis of prior effects on the BVI method was not performed. We chose to follow the recommendations of \citet{simpson2017penalising} to use penalizing complexity priors, as these had desirable properties and are designed to nicely fit INLA models. The parameters of our PC priors follow the default values in the \texttt{R-INLA} package, and we have not investigated how these could be tuned to better fit the data. This could be done to further solidify the results of the BVI method, but would also require more time and resources than what we had available in the scope of this thesis. 





\begin{itemize}
    \item Summarize the method. Similar to that of the project thesis. 
    \item State that it can be used across diciplines, and that a Bayesian approach is useful when prior information is available.
    \item Now the discussion really begins. State that the methodology for LMMs proved to imply that we have a proper decomposition of the $R^2$. Even though this was not a main focus in this thesis, the results of uncorrelated covariates and marginal and conditional $R^2$ values seem to be in line with the what one would expect. 
    \item State that we have addressed two main points from the project thesis, namely testing the methodology on real data and expanding it to handle GLMMs.
    \item Further, we allow for a covariance structure in the random effects, which is not possible in the project thesis.
    \item Emphasize that the results in this thesis are calculated based on theory from a subject that in itself has been subject to criticism. Therefore, the results should be interpreted with caution, especially when we also use the definitions of $R^2$ from Nakagawa, which may be oversimplified. (See last discussion section of project thesis)
\end{itemize}

Further work:
\begin{itemize}
    \item Extend the package to encompass the models with known distributional variance as in \citet{nakagawa2013general} and \citet{nakagawa2017}.
    \item No proofs were considered due to time limitation
    \item Random slopes could be featured, at least if one can say they improve the model.
    \item Correlated random effects (?)
\end{itemize}



HUSK Å NEVNE AT DET ER HELT NATURLIG AT VI FÅR RESULTATER SOM VARIERER LITT FRA GANG TIL GANG. DETTE KAN FORKLARE HVORFOR VI FOR EKSEMPEL IKKE TREFFER STOFFELS ESTIMATER OG BIOLOGENES ESTIMATER, MEN, BASERT PÅ SIMULERINGSSTUDIEN, FØLER VI OSS TRYGGE PÅ AT DENNE SPREDNINGEN IKKE ER FOR STOR, OG AT EN KJØRING AV METODEN KAN SEES PÅ SOM EN TILFELDIG PRØVE FRA EN FORDELING SOM ER SENTRERT RUNDT DEN KORREKTE VERDIEN.

LEGG TIL TO GITHUB LINKER, EN FOR PAKKEN OG EN FOR MASTEREN.

KAN DISKUTERES OM VI BURDE UNDERSØKT BEDRE PRIORS FOR ANIMAL MODEL OG DE ANDRE SIMULERINGENE
KAN DISKUTERES OM VI BURDE BRUKT HØYERE KORRELASJON, MEN DA TROR JEG IKKE MODELLENE VILLE BLITT KONVERGENTE
JEG TROR METODEN HELT FINT KLARER KATEGORISKE KOVARIATER NÅR DUMMY ENCODING BRUKES

DISKUTER SHRINKAGE PÅ RANDOM EFFECTS MED POSITIVT KORRELERTE FIXED EFFECTS OG INCREASE PÅ NEGATIVT KORRELERTE
DISKUTER HVORFOR POISSON MED HØY KORRELASJON GIR SÅ RARE RESULTATER

All code used to produced the presented results can be found on the authors Github, and a link to the repository is provided in \Cref{ap:github-repository_thesis}. In the Github, the fully developed package is available, with all files found in the repository linked in \Cref{ap:github-repository_package}. To make it easy to apply, the author has provided a usage example of the package in \Cref{ap:bayesian-importance}. This covers installation, simulates data, formulates and fits a model before drawing samples and obtaining relative importance plots and summary statistics. 

